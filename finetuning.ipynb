{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UTIL\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))  \n",
    "\n",
    "def show_boxes_on_image(raw_image, boxes):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(raw_image)\n",
    "    for box in boxes:\n",
    "      show_box(box, plt.gca())\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "\n",
    "def show_points_on_image(raw_image, input_points, input_labels=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(raw_image)\n",
    "    input_points = np.array(input_points)\n",
    "    if input_labels is None:\n",
    "      labels = np.ones_like(input_points[:, 0])\n",
    "    else:\n",
    "      labels = np.array(input_labels)\n",
    "    show_points(input_points, labels, plt.gca())\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "\n",
    "def show_points_and_boxes_on_image(raw_image, boxes, input_points, input_labels=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(raw_image)\n",
    "    input_points = np.array(input_points)\n",
    "    if input_labels is None:\n",
    "      labels = np.ones_like(input_points[:, 0])\n",
    "    else:\n",
    "      labels = np.array(input_labels)\n",
    "    show_points(input_points, labels, plt.gca())\n",
    "    for box in boxes:\n",
    "      show_box(box, plt.gca())\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_points_and_boxes_on_image(raw_image, boxes, input_points, input_labels=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(raw_image)\n",
    "    input_points = np.array(input_points)\n",
    "    if input_labels is None:\n",
    "      labels = np.ones_like(input_points[:, 0])\n",
    "    else:\n",
    "      labels = np.array(input_labels)\n",
    "    show_points(input_points, labels, plt.gca())\n",
    "    for box in boxes:\n",
    "      show_box(box, plt.gca())\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "\n",
    "def show_masks_on_image(raw_image, masks, scores):\n",
    "    if len(masks.shape) == 4:\n",
    "      masks = masks.squeeze()\n",
    "    if scores.shape[0] == 1:\n",
    "      scores = scores.squeeze()\n",
    "\n",
    "    nb_predictions = scores.shape[-1]\n",
    "    fig, axes = plt.subplots(1, nb_predictions, figsize=(15, 15))\n",
    "\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "      mask = mask.cpu().detach()\n",
    "      axes[i].imshow(np.array(raw_image))\n",
    "      show_mask(mask, axes[i])\n",
    "      axes[i].title.set_text(f\"Mask {i+1}, Score: {score.item():.3f}\")\n",
    "      axes[i].axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from PIL import Image\n",
    "from transformers import SamModel, SamProcessor\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import SamModel, SamProcessor\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(device)\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "\n",
    "sam = sam_model_registry[\"vit_h\"](checkpoint=\"./model/sam_vit_h_4b8939.pth\")\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of images found: 128\n",
      "Amount of masks found: 128\n"
     ]
    }
   ],
   "source": [
    "# Add images and masks to array\n",
    "\n",
    "import os\n",
    "\n",
    "panos_dir = \"./data/training/0000/directions\"\n",
    "masks_dir = \"./data/training/0000/direction_masks\"\n",
    "\n",
    "image_paths = []\n",
    "mask_paths = []\n",
    "\n",
    "for filename in os.listdir(panos_dir):\n",
    "\tif filename.endswith((\".jpg\", \".png\")):\n",
    "\t\timage_path = os.path.join(panos_dir, filename)\n",
    "\t\tmask_name = f\"mask_{os.path.splitext(filename)[0]}.png\" \n",
    "\t\tmask_path = os.path.join(masks_dir, mask_name)\n",
    "\n",
    "\t\tif os.path.exists(mask_path):\n",
    "\t\t\t\timage_paths.append(image_path)\n",
    "\t\t\t\tmask_paths.append(mask_path)\n",
    "\t\telse:\n",
    "\t\t\t\tprint(f\"No mask for {image_path} found\")\n",
    "\n",
    "print(f\"Amount of images found: {len(image_paths)}\")\n",
    "print(f\"Amount of masks found: {len(mask_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset definition\n",
    "\n",
    "class WindowSegmentationDataset(Dataset):\n",
    "  def __init__(self, image_paths, mask_paths, transform=None):\n",
    "    self.image_paths = image_paths\n",
    "    self.mask_paths = mask_paths\n",
    "    self.transform = transform\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.image_paths)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "    mask = Image.open(self.mask_paths[idx]).convert(\"L\")\n",
    "    \n",
    "    if (self.transform):\n",
    "      image = self.transform(image)\n",
    "      mask = self.transform(mask)\n",
    "      \n",
    "    return image, mask\n",
    "\n",
    "transform = transforms.Compose([\n",
    "\ttransforms.Resize((409, 204)),\n",
    " \ttransforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = WindowSegmentationDataset(image_paths, mask_paths, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "\tdef __init__(self, smooth=1.0):\n",
    "\t\tsuper(DiceLoss, self).__init__()\n",
    "\t\tself.smooth = smooth\n",
    "\n",
    "\tdef forward(self, pred, target):\n",
    "\t\tpred = torch.sigmoid(pred)  # Falls die Logits nicht schon gesigmoidet sind\n",
    "\t\tintersection = (pred * target).sum()\n",
    "\t\treturn 1 - (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
    "\n",
    "\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "\tdef __init__(self, bce_weight=0.5):\n",
    "\t\tsuper(BCEDiceLoss, self).__init__()\n",
    "\t\tself.bce = nn.BCEWithLogitsLoss()\n",
    "\t\tself.dice = DiceLoss()\n",
    "\n",
    "\tdef forward(self, pred, target):\n",
    "\t\treturn self.bce(pred, target) * 0.5 + self.dice(pred, target) * 0.5\n",
    "\n",
    "loss_fn = BCEDiceLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "\tr=16,\n",
    "\tlora_alpha=32,\n",
    "\tlora_dropout=0.1,\n",
    " \ttarget_modules=\"mask_decoder.layers.0.conv2d\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(model)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(10):\n",
    "  for batch in data_loader:\n",
    "    images, masks = batch\n",
    "    outputs = model(images)\n",
    "    loss = BCEDiceLoss()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rename\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "folder = \"./data/training/0000/direction_masks\"\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "  match = re.match(r\"(mask_(left|right|front|back))_mask_(.*\\.png)\", filename)\n",
    "  \n",
    "  if match:\n",
    "    new_name = f\"{match.group(1)}_{match.group(3)}\"\n",
    "    old_path = os.path.join(folder, filename)\n",
    "    new_path = os.path.join(folder, new_name)\n",
    "    \n",
    "    os.rename(old_path, new_path)\n",
    "    print(f\"Renamed: {filename} -> {new_name}\")\n",
    "    \n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
